\chapter{Background}
\label{chap:Background}

\section{Messages}
\label{sec:Messages}

In today's interconnected world, computer programs rarely exist in a vacuum.
Rather, they form one small part of a much larger \gls{soa} -
consisting of multiple services, jobs and scripts, all exchanging information in
the form of messages. These messages may adhere to a standard data-interchange
format (for example, \gls{json}). They may correspond to an agreed upon
specification (for example, \href{https://goo.gl/rjuP4C}{IEEE 1671-2010}).
Or they may simply be blobs of binary information transmitted over the network -
completely subject to the interpretation of the sender and received.
At a fundamental level, though, a message is simply a collection of bytes, to be
transmitted from point A, to point B.

\section{Message Brokers}
\label{sec:brokers}

\begin{figure}[ht]
  \centering
  \input{figures/directMessaging}
  \caption{Two services, A and B, directly exchanging messages}
  \label{fig:tikz:directMessaging}
\end{figure}

To understand the role message brokers typically play in \glspl{soa}, we first
examine the simplest method of transmitting bytes between two applications -
directly transmitting messages between two applications (shown in
Figure~\ref{fig:tikz:directMessaging}).

In this example, the application 'A' wishes to transmit a simple message (a
sequence of bytes) to application 'B', and does so in the simplest method
possible. This could involve making an \gls{rpc}, opening a Unix/\gls{tcp}
socket, or making a HTTP web request - for the purposes of this illustration the
exact mechanism by which bytes are transferred is unimportant, the fact that the
transfer takes place \emph{directly} between the two parties is all that
matters.

\begin{figure}[ht]
  \centering
  \input{figures/complexDirectMessaging}
  \caption{Ten services directly exchanging messages}
  \label{fig:tikz:complexDirectMessaging}
\end{figure}

This is a perfectly acceptable method of exchanging information between two
services at a small scale. However (and perhaps unfortunately), systems rarely
exist in pairs. One of the biggest issues with simple application-to-application
messaging is demonstrated in Figure~\ref{fig:tikz:complexDirectMessaging} - as
more nodes are added, the complexity of using direct connections increases
exponentially (requiring $n^2 - n$ connections, where $n$ is the number of
services)\footnote{Assuming each service needs to talk to all other services}.
Managing this complexity is difficult in a number of ways:

\begin{description}
  \item[Service discovery] \hfill \\
  Firstly, each program requires some mechanism of discovering an endpoint for
  all the other services it wishes to communicate with. Typically, this is
  either provided via configuration shipped with the program, or is available
  from some central repository. There are also, however, problems involved with
  keeping this information up to date - as the services with which a client
  machine communicates may not always be available on the same endpoints all of
  the time (Possibly due to dynamic network configuration via DHCP, or the
  migration of a service between servers).
  \item[Number of connections] \hfill \\
  As the number of services a program communicates with increases, so do the
  number of connections said program is required to maintain. This could be a
  non-issue if a connectionless protocol such as UDP (which has the distinct
  disadvantage of not having any deliverability guarantees). However, if a
  connection-oriented protocol such as TCP is used, there can be significant
  overhead associated with maintaining large numbers of
  connections\footnote{Although this is less of a problem with modern hardware:
  \url{http://c10m.robertgraham.com/p/manifesto.html}}\todo{Do we need a section
  on network protocols?}.
  \item[Readiness to receive] \hfill \\
  When a service sends a message across the network, the assumption is that the
  recipient of the message is ready to receive it.  However, this is not always
  the case. The recipient may be performing some other task when the message is
  sent - or may even be busy processing the previous message it received. There
  are several programming techniques which can be employed to reduce the
  possibility of lost messages - relying on  the built-in congestion-control
  protocols, such as those present in \gls{tcp}, and writing multithreaded or
  asynchronous (Section~\ref{sec:sub:concurrencyparallelism}) code. However,
  more often than not, application developers end up having to write code to
  handle communicating with services that are (for whatever reason) unavailable.
\end{description}

\begin{figure}[ht]
  \centering
  \input{figures/messageBroker}
  \caption{Ten services exchanging messages via a broker}
  \label{fig:tikz:messageBroker}
\end{figure}

Message brokers offer a layer of abstraction to developers wishing to exchange
messages between services. Rather than contacting the service directly, messages
are relayed via the broker (Figure~\ref{fig:tikz:messageBroker}). This not only
reduced the number of connections required for application to exchange messages
(Figure~\ref{fig:tikz:complexBrokerMessaging}), but also simplifies service
discovery. Each service need only know the connection details for the message
broker, and the name of the queue/topic (Sections \ref{sub:Queues} and
\ref{sub:Topics}) to send/receive messages on. The services are free to move
around independently of each other - which removes the need for complex service
discovery protocols. Additionally, by decoupling the sending and receiving of
messages (Section~\ref{sub:pubsub}) brokers can act as a buffer between
communicating processes, preventing the receiving process from becoming swamped
by incoming messages (\gls{dos}).

\begin{figure}[ht]
  \centering
  \input{figures/complexBrokerMessaging}
  \caption{Ten services exchanging messages via a broker}
  \label{fig:tikz:complexBrokerMessaging}
\end{figure}

\subsection{Pub/Sub}
\label{sub:pubsub}

Brief overview of the pub/sub model.

\subsection{Queues}
\label{sub:Queues}

Brief overview of the features/operation of a queue, in relation to a message broker.


\subsection{Topics}
\label{sub:Topics}

Brief overview of the features/operation of a topic, in relation to a message broker.

\subsection{Existing Brokers}
\label{sub:Existing Brokers}

Brief overview and comparison between some existing commercial/open-source
implementations, and their features.


\section{Broker Requirements}
\label{sec:requirements}

A message-broker is rather an unusual piece of software, due to the fact that is has very few functional requirements.

\subsection{Failure Handling}
\label{sub:Failure Handling}

The issue with gracefully handling communications failure in distributed systems
was illustrated in a 1988 paper by Xerox employees
Andrew Birrell and Bruce Nelson\cite{Birrell:1988:IRP:59309.59336}. They identified
three different semantics with which \glspl{rpc} could be executed:

\begin{description}
  \item[Exactly once] \hfill \\
    The ideal scenario is one in which messages are passed to their destination
    once, and exactly once. Typically, when failure does not occur during a
    message transfer this is trivial to assert - simply receiving an acknowledgement
    from the recipient of the message confirms this to be the case.
    Unfortunately, the same cannot be said when a response is not received from
    the recipient, for whatever reason (link failure/machine failure etc.).
    This is a typical illustration of the
    'Two Generals Problem'\cite{Gray:1978:NDB:647433.723863} - and is extremely
    difficult to guard against. As a result - most messaging systems adopt one
    of the following behavioural models in the event of failure.
  \item[At most once] \hfill \\
    In the event that a message is lost without acknowledgement - no attempt is made
    to redeliver the message. This is used in situations where duplicated messages
    pose a risk to overall system integrity - for example in most financial systems.
  \item[At least once] \hfill \\
    In the event that a message is lost without acknowledgement, attempts to
    redeliver the message continue until successful receipt is acknowledged.
    This is typically used in situations where message delivery is deemed more
    important than message uniqueness/ordering. For example, if the unacknowledged
    message is intended to trigger a cache refresh in the recipient system - the
    fact that the refresh may occur multiple times may be insignificant next to
    the risk that the refresh does not happen at all.
\end{description}

\subsection{Network Bandwidth Utilization}
\label{sub:Network Bandwidth Utilization}

In many situations (and in \gls{iot} devices in particular) network bandwidth is
a limiting resource. Message compression can be used in certain situations to
reduce overall bandwidth utilization of the broker - at the cost of increased
computational load on both the broker and consumer.

\subsection{Network latency}
\label{sub:Network latency}

Devices experiencing high degrees of network latency can have tremendous impact
on the overall \gls{rtt} of a given message. This can be compensated for through
intelligent packet stuffing (such as Nagel's algorithm)/jumbo frames (if supported)
by the network - all of which reduce the amount of overhead experienced by each
message.

\subsection{Network packet loss}
\label{sub:Network packet loss}

On networks experiencing a high rate of packet loss - error correcting protocols
like TCP can help ensure packet delivery at the IP layer. Additionally,
check-summing the messages can help guard against message corruption through lost
packets.

\subsection{Message power cost}
\label{sub:Message power cost}

Especially relevant for \gls{iot} and low-power devices - the amount of power
consumed whilst exchanging messages (which is directly linked to the number of
CPU cycles required to transmit/receive each message) can be an important
consideration when designing an applications. Message attributes which can
affect this include:

\begin{itemize}
  \item Message compression
  \item Message size
  \item IP Protocol
  \item Network conditions (requiring re-transmits/computing checksums etc.)
\end{itemize}

\subsection{Message throughput}
\label{sub:Message throughput}

Finally - the most obvious performance metric of a broker - the number of
messages it can process per second. This is impacted by all of the above
requirements, and can be maximized through the use of small, cheap messages,
with as little overhead as possible. Network protocol can make a large
difference here - with something like UDP being extremely cheap to send over the
wire (if inherently unreliable).

\section{GoLang}
\label{sec:GoLang}

\todo[inline]{Overview of GoLang}

\subsection{What is GoLang?}
\label{sub:What is GoLang?}

\todo[inline]{History/Purpose/Development}

\subsection{Concurrency vs Parallelism}
\label{sub:concurrencyparallelism}

\todo[inline]{Async IO vs multiple threads}

\subsection{Why do we need concurrency?}
\label{sub:Why do we need parallism}

\todo[inline]{Message broker functions - blocking vs non-blocking IO}

\subsection{Concurrency in GoLang}
\label{sub:Concurrency in GoLang}

\todo[inline]{GoRoutines/Channels etc.}

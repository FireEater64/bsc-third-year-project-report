\chapter{Design}
\label{chap:Design}

\section{Project philosophy}
\label{sec:Project philosophy}

Brief overview of the open development mentality ().

\section{SLA/QoS Specification}
\label{sec:SLA/QoS Specification}

One of the main goals of this project, was to produce a single message broker that
is capable of living up to multiple different \glspl{sla}, depending on what was
requested by the user/the current state of the network. These SLAs can be divided
into multiple categories:

\subsection{Failure Handling}
\label{sub:Failure Handling}

The issue with gracefully handling communications failure in distributed systems
was illustrated in a 1988 paper by Xerox employees
Andrew Birrell and Bruce Nelson\cite{Birrell:1988:IRP:59309.59336}. They identified
three different semantics with which \glspl{rpc} could be executed:

\begin{description}
  \item[Exactly once] \hfill \\
    The ideal scenario is one in which messages are passed to their destination
    once, and exactly once. Typically, when failure does not occur during a
    message transfer this is trivial to assert - simply receiving an acknowledgement
    from the recipient of the message confirms this to be the case.
    Unfortunately, the same cannot be said when a response is not received from
    the recipient, for whatever reason (link failure/machine failure etc.).
    This is a typical illustration of the
    'Two Generals Problem'\cite{Gray:1978:NDB:647433.723863} - and is extremely
    difficult to guard against. As a result - most messaging systems adopt one
    of the following behavioural models in the event of failure.
  \item[At most once] \hfill \\
    In the event that a message is lost without acknowledgement - no attempt is made
    to redeliver the message. This is used in situations where duplicated messages
    pose a risk to overall system integrity - for example in most financial systems.
  \item[At least once] \hfill \\
    In the event that a message is lost without acknowledgement, attempts to
    redeliver the message continue until successful receipt is acknowledged.
    This is typically used in situations where message delivery is deemed more
    important than message uniqueness/ordering. For example, if the unacknowledged
    message is intended to trigger a cache refresh in the recipient system - the
    fact that the refresh may occur multiple times may be insignificant next to
    the risk that the refresh does not happen at all.
\end{description}

\subsection{Network Bandwidth Utilization}
\label{sub:Network Bandwidth Utilization}

In many situations (and in \gls{iot} devices in particular) network bandwidth is
a limiting resource. Message compression can be used in certain situations to
reduce overall bandwidth utilization of the broker - at the cost of increased
computational load on both the broker and consumer.

\subsection{Network latency}
\label{sub:Network latency}

Devices experiencing high degrees of network latency can have tremendous impact
on the overall \gls{rtt} of a given message. This can be compensated for through
intelligent packet stuffing (such as Nagel's algorithm)/jumbo frames (if supported)
by the network - all of which reduce the amount of overhead experienced by each
message.

\subsection{Network packet loss}
\label{sub:Network packet loss}

On networks experiencing a high rate of packet loss - error correcting protocols
like TCP can help ensure packet delivery at the IP layer. Additionally,
check-summing the messages can help guard against message corruption through lost
packets.

\subsection{Message power cost}
\label{sub:Message power cost}

Especially relevant for \gls{iot} and low-power devices - the amount of power
consumed whilst exchanging messages (which is directly linked to the number of
CPU cycles required to transmit/receive each message) can be an important
consideration when designing an applications. Message attributes which can
affect this include:

\begin{itemize}
  \item Message compression
  \item Message size
  \item IP Protocol
  \item Network conditions (requiring re-transmits/computing checksums etc.)
\end{itemize}

\subsection{Message throughput}
\label{sub:Message throughput}

Finally - the most obvious performance metric of a broker - the number of messages
it can process per second. This is impacted by all of the above requirements,
and can be maximized through the use of small, cheap messages, with as little
overhead as possible. Network protocol can make a large difference here - with
something like UDP being extremely cheap to send over the wire
(if inherently unreliable).

The above axioms make an interesting optimization problem. The 'optimal' combination
of protocol and broker algorithm varies dramatically depending on the developer
requirements, as well as the operating environment of the broker/endpoints.

\section{Presentation interface}
\label{sec:presentation}

As a (primarily) middleware project - coming up with a compelling presentation
format is crucial. Broker metrics such as:

\begin{itemize}
  \item Messages/second (broken down by topic)
  \item (Average) End-to-end latency for each message
  \item Memory/Disk usage
  \item CPU utilization
  \item Pending messages
  \item Unacknowledged messages
  \item Total messages processed
\end{itemize}

And client metrics such as:

\begin{itemize}
  \item Messages sent
  \item Messages received
  \item Messages lost
\end{itemize}

Should be easily accessible, and visualized.

\section{Configuration}
\label{sec:Configuration}

As with most pieces of software - there are situations where the default behavior of a message broker requires adjustment to suit its operating environment. One example of this is the network port that the broker operates on, and which other applications will connect to in order to exchange messages. Whilst the default port (48879\footnote{A number chosen due to its memorable hexadecimal representation: \texttt{0xBEEF}} in the case of this broker) may be suitable in most cases, since no other 'well-known' applications use that particular port.\footnote{\url{https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers}}.

\subsection{Command-line configuration}
\label{sub:Command-line configuration}

A number of these configurable parameters make sense to expose as command-line parameters, specified at application start time. The available parameters can be exposed using the \texttt{--help} parameter, the output of which can be seen in Listing~\ref{lst:gamqHelpOutput}

\begin{listing}[ht]
  \centering
  \inputminted{bash}{code/gamqHelpOutput}
  \caption{Output of running the broker with the --help flag}
  \label{lst:gamqHelpOutput}
\end{listing}

\subsection{File-based configuration}
\label{sub:File-based configuration}

Whilst specifying arguments on the command line gives flexibility, there are certain options that, whilst configurable, are either too numerous, or change too infrequently to justify command-line flags. One major example of this is the log configuration for the broker - specifying the format, and location of messages logged using the \href{https://github.com/cihub/seelog}{Seelog} library. An example log configuration can be seen in Listing~\ref{lst:seelogConfig}.

\begin{listing}[ht]
  \centering
  \inputminted{xml}{code/gamq/config/logconfig.xml}
  \caption{Example Seelog configuration file for gamq.}
  \label{lst:seelogConfig}
\end{listing}

\section{GoLang}
\label{sec:GoLang}

\todo[inline]{Overview of GoLang}

\subsection{What is GoLang?}
\label{sub:What is GoLang?}

\todo[inline]{History/Purpose/Development}

\subsection{Concurrency vs Parallelism}
\label{sub:Concurrency vs Parallism}

\todo[inline]{Async IO vs multiple threads}

\subsection{Why do we need concurrency?}
\label{sub:Why do we need parallism}

\todo[inline]{Message broker functions - blocking vs non-blocking IO}

\subsection{Concurrency in GoLang}
\label{sub:Concurrency in GoLang}

\todo[inline]{GoRoutines/Channels etc.}
